{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "Created layers of piping\n",
    "1. Data Types (categorical/numerical)\n",
    "2. Combinging two types\n",
    "3. Piping model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "\n",
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated data (>0.9) from correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_correlated = ['Insurance_History_4','Insurance_History_7','Insurance_History_9', #category\n",
    " 'Family_Hist_4', #numeric\n",
    " 'Medical_History_26','Medical_History_36', #cat\n",
    " 'Medical_Keyword_11','Medical_Keyword_23','Medical_Keyword_48'] #numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Custom catgorical and numerical transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "        \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):\n",
    "        columns = list(X.columns)# since this is being fed all the categorical data, I can do this\n",
    "        \n",
    "        #Drop highly correlated\n",
    "        drop_list = ['Insurance_History_4','Insurance_History_7','Insurance_History_9','Medical_History_26','Medical_History_36']\n",
    "#         X.drop(drop_list,inplace = True, axis = 1)\n",
    "        \n",
    "#         for name in drop_list:\n",
    "#             columns.remove(name)\n",
    "#         Xfm = pd.get_dummies(data = X, columns = columns, prefix = columns,drop_first = True)\n",
    "        Xfm = pd.get_dummies(X)\n",
    "        \n",
    "        return Xfm.values\n",
    "#         return X[ self.feature_names ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use .loc[row,indexer] instead of copying a slice\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor\n",
    "    def __init__( self, num_keywords = True, avg_family = True):\n",
    "        self._num_keywords = num_keywords\n",
    "        self.avg_family = avg_family\n",
    "        \n",
    "    #Return self, nothing else to do here\n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "        \n",
    "    #Custom transform method we wrote that creates aformentioned features and drops redundant ones \n",
    "    def transform(self, X, y = None): # X's type is a dataframe\n",
    "        #feature engineering sum of keywords \n",
    "        if self._num_keywords:\n",
    "            X.loc[:,'num_keywords'] = sum([X[column] for column in ['Medical_Keyword_' + str(i) for i in range(1,49)]])\n",
    "\n",
    "    #family_hist_2 -> 5\n",
    "        if self.avg_family: #will create columns with NaN from 0 + 0 + 0 + 0\n",
    "            X.loc[:,'avg_family'] = X.loc[:,['Family_Hist_2','Family_Hist_3','Family_Hist_4','Family_Hist_5']].mean(axis = 1, skipna= True)\n",
    "            X.drop(['Family_Hist_2','Family_Hist_3','Family_Hist_4','Family_Hist_5'],axis = 1, inplace = True)\n",
    "        \n",
    "        #solution to NaN value\n",
    "        X.loc[:,'avg_family'] = np.where(X.loc[:,'avg_family'].isna(),0.5,X.loc[:,'avg_family'])\n",
    "        \n",
    "        #imput employment info and insurance history 5 using mean\n",
    "        for column in ['Employment_Info_1','Employment_Info_4','Employment_Info_6','Insurance_History_5']:\n",
    "            conditions = [ X.loc[:,column].isnull() ]\n",
    "            out = [X.loc[:,column].mean()]\n",
    "            X.loc[:,column] = np.select(conditions,out,X.loc[:,column])\n",
    "            \n",
    "        #fill in nan-vales with 0 in keywords and drop highly correlated\n",
    "        X.fillna(0,inplace = True)\n",
    "        X.drop(['Medical_Keyword_11','Medical_Keyword_23','Medical_Keyword_48'],inplace = True, axis = 1)\n",
    "\n",
    "        return X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = 'Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41'.split(', ')\n",
    "cont = 'Product_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5'.split(', ')\n",
    "disc = 'Medical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32'.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Combining selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categrical features to pass down the categorical pipeline \n",
    "categorical_features = cats\n",
    "\n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = ['Medical_Keyword_' + str(i) for i in range(1,49)] + cont + disc\n",
    "\n",
    "#Defining the steps in the categorical pipeline \n",
    "categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ), \n",
    "                                          \n",
    "                                  ( 'cat_transformer', CategoricalTransformer() ), \n",
    "                                                                           ] )\n",
    "#Defining the steps in the numerical pipeline     \n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(numerical_features) ),\n",
    "                                        \n",
    "                                  ( 'num_transformer', NumericalTransformer(numerical_features) ),\n",
    "                                       ])\n",
    "\n",
    "#Combining numerical and categorical piepline into one full big pipeline horizontally using FeatureUnion\n",
    "full_pipeline = FeatureUnion( transformer_list = [ ( 'categorical_pipeline', categorical_pipeline ), \n",
    "                                        \n",
    "                                                  ( 'numerical_pipeline', numerical_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "cohen = make_scorer(cohen_kappa_score) #custom scorer using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "Read in data and run a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Response', axis = 1)\n",
    "#You can covert the target variable to numpy \n",
    "y = data['Response'].values \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Get the full pipeline and classifier into another pipeline. \n",
    "<br>Manually tested parameters and also utilized some for-looping through list classifier of parameters, but not shown\n",
    "<br>Attempt at integrating gridsearch into pipeline is at bottom of notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ \n",
    "    ( 'full_pipeline', full_pipeline ),\n",
    "\n",
    "        ( 'rfm',XGBClassifier(n_jobs = -1, objective= 'multi:softmax',\n",
    "                             eval_metric = 'merror', n_estimators =  300,\n",
    "                             verbosity = 0, max_depth = 100) )\n",
    "] )\n",
    "\n",
    "full_pipeline_m.fit(X_train,y_train)\n",
    "\n",
    "y_pred = full_pipeline_m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.5753978277342763\n",
      "F1 score is:  0.5513210689076509\n",
      "Cohen score is:  0.45712380345234527\n"
     ]
    }
   ],
   "source": [
    "# print('Accuracy score is: ', accuracy_score(y_test, y_pred))\n",
    "# print('F1 score is: ',f1_score(y_test, y_pred,average='weighted'))\n",
    "# print('Cohen score is: ',cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.5770817546518481\n",
      "F1 score is:  0.5536111241401745\n",
      "Cohen score is:  0.4598570344591989\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score is: ', accuracy_score(y_test, y_pred))\n",
    "print('F1 score is: ',f1_score(y_test, y_pred,average='weighted'))\n",
    "print('Cohen score is: ',cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10230,   349],\n",
       "        [  994,   304]],\n",
       "\n",
       "       [[10131,   436],\n",
       "        [  951,   359]],\n",
       "\n",
       "       [[11595,    75],\n",
       "        [  143,    64]],\n",
       "\n",
       "       [[11454,   139],\n",
       "        [  149,   135]],\n",
       "\n",
       "       [[10409,   349],\n",
       "        [  510,   609]],\n",
       "\n",
       "       [[ 8406,  1222],\n",
       "        [ 1040,  1209]],\n",
       "\n",
       "       [[ 9500,   819],\n",
       "        [  874,   684]],\n",
       "\n",
       "       [[ 6391,  1634],\n",
       "        [  362,  3490]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    5124\n",
       "6    2431\n",
       "7    1503\n",
       "5     958\n",
       "2     795\n",
       "1     653\n",
       "4     274\n",
       "3     139\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred,columns = ['Response'])['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    3852\n",
       "6    2249\n",
       "7    1558\n",
       "2    1310\n",
       "1    1298\n",
       "5    1119\n",
       "4     284\n",
       "3     207\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test,columns = ['Response'])['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 'xgb_final'\n",
    "with open('model_{}.pickle'.format(model_num), 'wb') as f:\n",
    "    pickle.dump(full_pipeline_m, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Opening Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_num = 'xgb_final'\n",
    "# with open('model_xgb_final.pickle'.format(model_num), 'rb') as f:\n",
    "#     full_pipeline_m = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='merror',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=100,\n",
       "              min_child_weight=1, missing=nan, n_estimators=300, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline_m['rfm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(full_pipeline_m['rfm'],max_num_features = 10)\n",
    "plt.rcParams['figure.figsize'] = [16, 16]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   1               1             D3              26        0.487179   \n",
       "1   3               1             A2              26        0.076923   \n",
       "2   4               1             D3              26        0.144667   \n",
       "3   9               1             A1              26        0.151709   \n",
       "4  12               1             A1              26        0.076923   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  ...  \\\n",
       "0               2               3               1  0.611940  0.781818  ...   \n",
       "1               2               3               1  0.626866  0.727273  ...   \n",
       "2               2               3               1  0.582090  0.709091  ...   \n",
       "3               2               1               1  0.522388  0.654545  ...   \n",
       "4               2               3               1  0.298507  0.672727  ...   \n",
       "\n",
       "   Medical_Keyword_39  Medical_Keyword_40  Medical_Keyword_41  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_42  Medical_Keyword_43  Medical_Keyword_44  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_45  Medical_Keyword_46  Medical_Keyword_47  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_48  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "y_pred = full_pipeline_m.predict( test_data ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19765"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred) #19765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe to save into proper format\n",
    "pred_res = pd.DataFrame(y_pred, columns = ['Response'])\n",
    "pred_id = test_data['Id']\n",
    "final = pd.concat([pred_id,pred_res], axis = 1)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('prudential_pred.csv',index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps, implementing grid search into pipeline\n",
    "- Currently there is a fittransform error from the GridSearch's scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do not run\n",
    "X = data.drop('Response', axis = 1)\n",
    "y = data['Response'].values \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 42 )\n",
    "\n",
    "#The full pipeline as a step in another pipeline with an estimator as the final step\n",
    "full_pipeline_m = Pipeline( steps = [ \n",
    "    ( 'full_pipeline', full_pipeline),\n",
    "    ('rfm',XGBClassifier(n_jobs = -1,))\n",
    "#     ('rfm', RandomForestClassifier(random_state = 0, class_weight = 'balanced')),\n",
    "# ( 'model', RandomForestClassifier(n_jobs = -1,verbose = 1, random_state = 0, class_weight = 'balanced'),) #score = 0.41, 0.50933\n",
    "] )\n",
    "\n",
    "#Grid search\n",
    "\n",
    "grid = {'rfm__max_depth': [2, 6, 10], \n",
    "         'rfm__min_samples_split': [5, 10]\n",
    "       }\n",
    "\n",
    "# Create the grid, with \"pipe\" as the estimator\n",
    "gridsearch = GridSearchCV(estimator=full_pipeline_m, \n",
    "                          param_grid=grid, \n",
    "                          scoring=cohen, \n",
    "                          cv=5,\n",
    "#                           error_score = 0,\n",
    "#                           refit = False\n",
    "                         )\n",
    "\n",
    "# Fit using grid search\n",
    "# gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the test score\n",
    "# gridsearch.score(X_test, y_test)\n",
    "\n",
    "#Can call fit on it just like any other pipeline\n",
    "# full_pipeline_m.fit( X_train, y_train )\n",
    "\n",
    "#Can predict with it like any other pipeline\n",
    "# y_pred = full_pipeline_m.predict( X_test ) \n",
    "# y_pred = gridsearch.predict( X_test ) \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another next step: Mission of getting the important features' names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01010036 0.00437335 0.00638613 0.00402752 0.00668538 0.00436523\n",
      " 0.         0.00416128 0.00443942 0.01883804 0.00336411 0.00433515\n",
      " 0.01486567 0.011138   0.01198572 0.00391592 0.00980122 0.00367338\n",
      " 0.00310102 0.00480563 0.00341944 0.00435238 0.03712924 0.01611847\n",
      " 0.00647504 0.00696166 0.0048858  0.00366417 0.00944866 0.00521111\n",
      " 0.00705771 0.00507368 0.00384979 0.00818194 0.00781101 0.00613259\n",
      " 0.0106976  0.00417812 0.00625978 0.01449963 0.00381481 0.00853573\n",
      " 0.00900088 0.00372942 0.01692121 0.01087124 0.00645911 0.00400743\n",
      " 0.00650438 0.00518068 0.01015138 0.00803514 0.02248611 0.00338265\n",
      " 0.00476721 0.00500423 0.00547179 0.00347732 0.00690357 0.00892792\n",
      " 0.00446831 0.00408059 0.00614647 0.00440308 0.00568416 0.00543733\n",
      " 0.00561155 0.00543822 0.00611986 0.00414895 0.00360847 0.00365484\n",
      " 0.00457363 0.00543128 0.00392229 0.05657213 0.00580435 0.00590406\n",
      " 0.0059951  0.005959   0.00444816 0.005534   0.00588788 0.00585536\n",
      " 0.00954679 0.00583403 0.04370526 0.00515741 0.00496884 0.00655451\n",
      " 0.00463121 0.00654107 0.00645104 0.00482165 0.00618027 0.00425299\n",
      " 0.00625913 0.0048967  0.00551602 0.00611879 0.00510656 0.00757566\n",
      " 0.00530109 0.00575108 0.00496104 0.01425084 0.00651918 0.00504332\n",
      " 0.0163103  0.0056045  0.00498168 0.0125347  0.00546065 0.00762989\n",
      " 0.00508693 0.00506137 0.0068181  0.00621072 0.0078157  0.00449932\n",
      " 0.00343094 0.00370283 0.01099694 0.00343697 0.00412007 0.00330244\n",
      " 0.00367266 0.00349918 0.00990626 0.01382542 0.01338898 0.00933424\n",
      " 0.00578611 0.00354707]\n"
     ]
    }
   ],
   "source": [
    "print(full_pipeline_m.named_steps[\"rfm\"].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop(['Insurance_History_4','Insurance_History_7','Insurance_History_9','Medical_History_26','Medical_History_36'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Insurance_History_4','Insurance_History_7','Insurance_History_9','Medical_History_26','Medical_History_36']:\n",
    "    cats.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Employment_Info_1</th>\n",
       "      <th>Employment_Info_4</th>\n",
       "      <th>Employment_Info_6</th>\n",
       "      <th>Insurance_History_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_History_35_3</th>\n",
       "      <th>Medical_History_37_2</th>\n",
       "      <th>Medical_History_37_3</th>\n",
       "      <th>Medical_History_38_2</th>\n",
       "      <th>Medical_History_39_2</th>\n",
       "      <th>Medical_History_39_3</th>\n",
       "      <th>Medical_History_40_2</th>\n",
       "      <th>Medical_History_40_3</th>\n",
       "      <th>Medical_History_41_2</th>\n",
       "      <th>Medical_History_41_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.148536</td>\n",
       "      <td>0.323008</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.272288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.428780</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.352438</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.234310</td>\n",
       "      <td>0.424046</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59376</th>\n",
       "      <td>79142</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>0.519103</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59377</th>\n",
       "      <td>79143</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.403766</td>\n",
       "      <td>0.551119</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59378</th>\n",
       "      <td>79144</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.246862</td>\n",
       "      <td>0.360969</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59379</th>\n",
       "      <td>79145</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.276151</td>\n",
       "      <td>0.462452</td>\n",
       "      <td>0.038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59380</th>\n",
       "      <td>79146</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.382845</td>\n",
       "      <td>0.539563</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59381 rows Ã— 827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Product_Info_4   Ins_Age        Ht        Wt       BMI  \\\n",
       "0          2        0.076923  0.641791  0.581818  0.148536  0.323008   \n",
       "1          5        0.076923  0.059701  0.600000  0.131799  0.272288   \n",
       "2          6        0.076923  0.029851  0.745455  0.288703  0.428780   \n",
       "3          7        0.487179  0.164179  0.672727  0.205021  0.352438   \n",
       "4          8        0.230769  0.417910  0.654545  0.234310  0.424046   \n",
       "...      ...             ...       ...       ...       ...       ...   \n",
       "59376  79142        0.230769  0.074627  0.709091  0.320084  0.519103   \n",
       "59377  79143        0.230769  0.432836  0.800000  0.403766  0.551119   \n",
       "59378  79144        0.076923  0.104478  0.745455  0.246862  0.360969   \n",
       "59379  79145        0.230769  0.507463  0.690909  0.276151  0.462452   \n",
       "59380  79146        0.076923  0.447761  0.781818  0.382845  0.539563   \n",
       "\n",
       "       Employment_Info_1  Employment_Info_4  Employment_Info_6  \\\n",
       "0                  0.028            0.00000                NaN   \n",
       "1                  0.000            0.00000             0.0018   \n",
       "2                  0.030            0.00000             0.0300   \n",
       "3                  0.042            0.00000             0.2000   \n",
       "4                  0.027            0.00000             0.0500   \n",
       "...                  ...                ...                ...   \n",
       "59376              0.020            0.00000             0.0250   \n",
       "59377              0.100            0.00001             0.3500   \n",
       "59378              0.035            0.00000                NaN   \n",
       "59379              0.038                NaN                NaN   \n",
       "59380              0.123                NaN             0.3000   \n",
       "\n",
       "       Insurance_History_5  ...  Medical_History_35_3  Medical_History_37_2  \\\n",
       "0                 0.000667  ...                     0                     1   \n",
       "1                 0.000133  ...                     0                     1   \n",
       "2                      NaN  ...                     0                     1   \n",
       "3                      NaN  ...                     0                     1   \n",
       "4                      NaN  ...                     0                     1   \n",
       "...                    ...  ...                   ...                   ...   \n",
       "59376                  NaN  ...                     0                     1   \n",
       "59377             0.000267  ...                     0                     1   \n",
       "59378                  NaN  ...                     0                     1   \n",
       "59379                  NaN  ...                     0                     1   \n",
       "59380                  NaN  ...                     0                     1   \n",
       "\n",
       "       Medical_History_37_3  Medical_History_38_2  Medical_History_39_2  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "59376                     0                     0                     0   \n",
       "59377                     0                     0                     0   \n",
       "59378                     0                     0                     0   \n",
       "59379                     0                     0                     0   \n",
       "59380                     0                     0                     0   \n",
       "\n",
       "       Medical_History_39_3  Medical_History_40_2  Medical_History_40_3  \\\n",
       "0                         1                     0                     1   \n",
       "1                         1                     0                     1   \n",
       "2                         1                     0                     1   \n",
       "3                         1                     0                     1   \n",
       "4                         1                     0                     1   \n",
       "...                     ...                   ...                   ...   \n",
       "59376                     1                     0                     1   \n",
       "59377                     1                     0                     1   \n",
       "59378                     1                     0                     1   \n",
       "59379                     1                     0                     1   \n",
       "59380                     1                     0                     1   \n",
       "\n",
       "       Medical_History_41_2  Medical_History_41_3  \n",
       "0                         0                     1  \n",
       "1                         0                     0  \n",
       "2                         0                     0  \n",
       "3                         0                     0  \n",
       "4                         0                     0  \n",
       "...                     ...                   ...  \n",
       "59376                     0                     1  \n",
       "59377                     0                     0  \n",
       "59378                     0                     0  \n",
       "59379                     0                     1  \n",
       "59380                     0                     0  \n",
       "\n",
       "[59381 rows x 827 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data = d, columns = cats, prefix = cats, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.drop(['Insurance_History_4','Insurance_History_7','Insurance_History_9','Medical_History_26','Medical_History_36'],inplace = True, axis = 1)\n",
    "d.drop(['Medical_Keyword_11','Medical_Keyword_23','Medical_Keyword_48'],inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Family_Hist_4'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Source: https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
